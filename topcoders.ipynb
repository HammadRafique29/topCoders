{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scraping Develpoers Data from TopCoders using Public API & Selnium.**\n",
    "#### **Flow & Working of Code:**\n",
    " - Get Challenges:\n",
    "    - Active Challenges [**Block-1**]\n",
    "    - Past Challenges   [**Block-2**]\n",
    "    - We are going to extract developers profiles from these challenges.\n",
    " - Get Developers RAW Data:\n",
    "    - Provide the path of Challenges Json File [**Block-4**].\n",
    " - Get Developers Traits & Statictics:\n",
    "    - RAW Developers Data File Used As Input [**Block-5**]\n",
    " - Convert the Developers Profiles Json into CSV:\n",
    "    - Developers Profiles File Used As Input [**Block-6**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install tqdm\n",
    "%pip install undetected_chromedriver\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "currentTime = datetime.datetime.now()\n",
    "WORKING_SESSION = os.path.join(CURRENT_DIR, f\"SESSION_{currentTime.day}_{currentTime.hour}_{currentTime.minute}\")\n",
    "BIN_DIR = os.path.join(WORKING_SESSION, \"bin\")\n",
    "LOG_DIR = os.path.join(WORKING_SESSION, \"log\")\n",
    "LOG_FILE = os.path.join(LOG_DIR, \"log.json\")\n",
    "\n",
    "if not os.path.exists(WORKING_SESSION): os.makedirs(WORKING_SESSION)\n",
    "if not os.path.exists(BIN_DIR): os.makedirs(BIN_DIR)\n",
    "if not os.path.exists(LOG_DIR): os.makedirs(LOG_DIR)\n",
    "if not os.path.exists(LOG_FILE): \n",
    "    with open(LOG_FILE, \"w\") as f: f.write(json.dumps({}))\n",
    "\n",
    "\n",
    "url = \"https://api.topcoder.com/v5/challenges/\"\n",
    "headers = {\n",
    "    \"accept\": \"*/*\",\n",
    "    \"accept-language\": \"en-US,en;q=0.9\",\n",
    "    \"app-version\": \"1.1.0\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"if-none-match\": \"W/\\\"14029-03jo/8tgikL7RQIliQ90l5HcP4g\\\"\",\n",
    "    \"priority\": \"u=1, i\",\n",
    "    \"sec-ch-ua\": \"\\\"Chromium\\\";v=\\\"124\\\", \\\"Microsoft Edge\\\";v=\\\"124\\\", \\\"Not-A.Brand\\\";v=\\\"99\\\"\",\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": \"\\\"Windows\\\"\",\n",
    "    \"sec-fetch-dest\": \"empty\",\n",
    "    \"sec-fetch-mode\": \"cors\",\n",
    "    \"sec-fetch-site\": \"same-site\",\n",
    "    \"Referer\": \"https://www.topcoder.com/\",\n",
    "    \"Referrer-Policy\": \"strict-origin-when-cross-origin\"\n",
    "}\n",
    "active_challenge_params = {\n",
    "    \"status\": \"Active\",\n",
    "    \"perPage\": \"50\",\n",
    "    \"page\": \"10\",\n",
    "    \"sortBy\": \"startDate\",\n",
    "    \"sortOrder\": \"desc\",\n",
    "    \"tracks[]\": [\"Dev\", \"Des\", \"DS\", \"QA\"],\n",
    "    \"types[]\": [\"CH\", \"F2F\", \"MM\", \"TSK\"]\n",
    "}\n",
    "past_challenge_params = active_challenge_params\n",
    "past_challenge_params['status'] = \"Completed\"\n",
    "past_challenge_params['perPage'] = '100'\n",
    "past_challenge_params['page'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap Active Challenges from TopCoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "SCRAP TOPCODERS Active CHALLENGES\n",
      "##################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 100 Challenges Found.\n",
      " DATA SAVED LOCATION: 'c:\\Users\\PMLS\\Desktop\\topCoders\\topCoders\\SESSION_24_6_49\\bin\\activeChallenges.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ACTIVE_CHALLENGES_FILE = os.path.join(BIN_DIR, \"activeChallenges.json\")\n",
    "if not os.path.exists(ACTIVE_CHALLENGES_FILE): \n",
    "    with open(ACTIVE_CHALLENGES_FILE, \"w\") as f: f.write(json.dumps({}))\n",
    "\n",
    "with open(LOG_FILE, \"r\") as f: log = json.loads(f.read())\n",
    "try:\n",
    "    with open(ACTIVE_CHALLENGES_FILE, \"r\") as f: activeChallenges = json.loads(f.read())\n",
    "    if not activeChallenges: activeChallenges = []\n",
    "except: activeChallenges = []\n",
    "\n",
    "\n",
    "os.system('cls')\n",
    "print(f\"{'#'*50}\")\n",
    "print(f\"SCRAP TOPCODERS Active CHALLENGES\")\n",
    "print(f\"{'#'*50}\\n\")\n",
    "\n",
    "startPages = int(input(\"Page to Start From: \"))\n",
    "endPages = int(input(\"Ending Limit of Page: \"))\n",
    "\n",
    "if 'activeChallengeScan' in log:\n",
    "    if int(startPages)>=log['activeChallengeScan'][0] and int(startPages) <= log['activeChallengeScan'][1]:\n",
    "        print(f\"\\nWe have Found You have Made A Request Recently Of {log['activeChallengeScan']} Pages.\")\n",
    "        print(f\"Please Make Sure, If the Data Is In Current Dir, It Will Cause Duplication Of Data.\")\n",
    "        print(f\"Its Up To You, To Start From Stretch Or Start The Pages Scan From Last Scan.\\n\")\n",
    "        choice = input(\"Enter new page value or go with above (y/n): \")\n",
    "        if choice.lower() in ['y', 'yes']:\n",
    "            os.system('cls')\n",
    "            startPages = int(input(\"Page to Start From: \"))\n",
    "            endPages = int(input(\"Ending Limit of Page: \"))\n",
    "            print(\"\")\n",
    "        else: pass\n",
    "\n",
    "\n",
    "for i in tqdm(range(startPages, endPages+1)):\n",
    "    active_challenge_params['page'] = f\"{i}\"\n",
    "    response = requests.get(url, headers=headers, params=active_challenge_params).json()\n",
    "    for chl in response: \n",
    "        if \"id\" in chl.keys(): activeChallenges.append(chl)\n",
    "\n",
    "\n",
    "log['activeChallengeScan'] = [startPages, endPages]\n",
    "with open(LOG_FILE, \"w\") as f: log = f.write(json.dumps(log))\n",
    "with open(ACTIVE_CHALLENGES_FILE, \"w\") as f: f.write(json.dumps(activeChallenges))\n",
    "print(f\"\\n {len(activeChallenges)} Challenges Found.\\n DATA SAVED LOCATION: '{ACTIVE_CHALLENGES_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap Past Completed Challenges from TopCoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "SCRAP TOPCODERS PAST CHALLENGES\n",
      "##################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 100 Challenges Found...\n",
      " DATA SAVED: 'c:\\Users\\PMLS\\Desktop\\topCoders\\topCoders\\SESSION_24_6_49\\bin\\pastChallenges.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PAST_CHALLENGES_FILE = os.path.join(BIN_DIR, \"pastChallenges.json\")\n",
    "if not os.path.exists(PAST_CHALLENGES_FILE): \n",
    "    with open(PAST_CHALLENGES_FILE, \"w\") as f: f.write(json.dumps({}))\n",
    "\n",
    "os.system('cls')\n",
    "print(f\"{'#'*50}\")\n",
    "print(f\"SCRAP TOPCODERS PAST CHALLENGES\")\n",
    "print(f\"{'#'*50}\\n\")\n",
    "\n",
    "startPages = int(input(\"Page to Start From: \"))\n",
    "endPages = int(input(\"Ending Limit of Page: \"))\n",
    "\n",
    "\n",
    "with open(LOG_FILE, \"r\") as f: log = json.loads(f.read())\n",
    "try:\n",
    "    with open(PAST_CHALLENGES_FILE, \"r\") as f: pastChallenges = json.loads(f.read())\n",
    "    if not pastChallenges: pastChallenges = []\n",
    "except: pastChallenges = []\n",
    "\n",
    "if 'pastChallengeScan' in log:\n",
    "    if int(startPages)>=log['pastChallengeScan'][0] and int(startPages) <= log['pastChallengeScan'][1]:\n",
    "        print(f\"\\nWe have Found You have Made A Request Recently Of {log['pastChallengeScan']} Pages.\")\n",
    "        print(f\"Please Make Sure, If the Data Is In Current Dir, It Will Cause Duplication Of Data.\")\n",
    "        print(f\"Its Up To You, To Start From Stretch Or Start The Pages Scan From Last Scan.\\n\")\n",
    "        choice = input(\"Enter new page value or go with above (y/n): \")\n",
    "        if choice.lower() in ['y', 'yes']:\n",
    "            os.system('cls')\n",
    "            startPages = int(input(\"Page to Start From: \"))\n",
    "            endPages = int(input(\"Ending Limit of Page: \"))\n",
    "            print(\"\")\n",
    "        else: pass\n",
    "\n",
    "\n",
    "for i in tqdm(range(startPages, endPages+1)):\n",
    "    past_challenge_params['page'] = f\"{i}\"\n",
    "    response = requests.get(url, headers=headers, params=past_challenge_params).json()\n",
    "    for chl in response: \n",
    "        if \"id\" in chl.keys(): pastChallenges.append(chl)\n",
    "\n",
    "with open(PAST_CHALLENGES_FILE, \"w\") as f: f.write(json.dumps(pastChallenges))\n",
    "print(f\"\\n {len(pastChallenges)} Challenges Found...\\n DATA SAVED: '{PAST_CHALLENGES_FILE}'\")\n",
    "\n",
    "log['pastChallengeScan'] = [startPages, endPages]\n",
    "with open(LOG_FILE, \"w\") as f: log = f.write(json.dumps(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CHROME_DRIVER:\n",
    "    def __init__(self):\n",
    "        self.RUNNING = False\n",
    "        self.Initialize_driver()\n",
    "    \n",
    "    def Initialize_driver(self):\n",
    "        try:\n",
    "            chrome_options = uc.ChromeOptions()\n",
    "            chrome_options.headless = False\n",
    "            chrome_options.arguments.extend([\"--no-sandbox\", \"--disable-setuid-sandbox\"])\n",
    "            chrome_options.add_argument('--no-sandbox')\n",
    "            chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "            chrome_options.add_argument(\"--incognito\")\n",
    "            chrome_options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "            chrome_options.add_argument('--disable-application-cache')\n",
    "            chrome_options.add_argument('--disable-cache')\n",
    "            chrome_options.add_argument('--disable-component-update')\n",
    "            chrome_options.add_argument('--disable-extensions')\n",
    "            chrome_options.add_argument('--disable-default-apps')\n",
    "            chrome_options.add_argument(\"--disable-backgrounding-occluded-windows\")\n",
    "            chrome_options.add_argument(\"--start-minimized\")\n",
    "            chrome_options.add_argument('--disable-features=OptimizationGuideModelDownloading,OptimizationHintsFetching,OptimizationTargetPrediction,OptimizationHints')\n",
    "            self.driver = uc.Chrome(options=chrome_options)\n",
    "            time.sleep(2)\n",
    "            self.RUNNING = True\n",
    "        except Exception as e: print(e)\n",
    "        \n",
    "    def getDriver(self, url):\n",
    "        if not self.RUNNING:  self.Initialize_driver()\n",
    "        while True:\n",
    "            try:\n",
    "                self.driver.get(url)\n",
    "                time.sleep(1)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                self.Initialize_driver()\n",
    "                continue\n",
    "        return self.driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAP DEVELOPERS DATA USING SELENIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers['Referer'] = \"https://profiles.topcoder.com/\"\n",
    "\n",
    "DEVELOPERS_FILE = os.path.join(BIN_DIR, \"developers.json\")\n",
    "if not os.path.exists(DEVELOPERS_FILE): \n",
    "    with open(DEVELOPERS_FILE, \"w\") as f: f.write(json.dumps([{}]))\n",
    "\n",
    "def readDevData():\n",
    "    readedData = None\n",
    "    with open(DEVELOPERS_FILE, \"r\") as f: readedData = json.loads(f.read())\n",
    "    return readedData\n",
    "\n",
    "def saveDevData(data): \n",
    "    with open(DEVELOPERS_FILE, \"w\") as f: f.write(json.dumps(data))\n",
    "    \n",
    "    \n",
    "fileName = input(\"Enter Challenges File Path: \")\n",
    "try:\n",
    "    CHALLENGES = None\n",
    "    with open(r\"{}\".format(fileName), \"r\") as f: CHALLENGES = json.loads(f.read())\n",
    "\n",
    "    USER_DATA = readDevData()\n",
    "    print(f\"Got {len(USER_DATA[0])} Dev\")\n",
    "    WEBDRIVER = CHROME_DRIVER()\n",
    "    driver = None\n",
    "    for index, chl in enumerate(tqdm(CHALLENGES, desc=\"Processing challenges\")):\n",
    "        try: \n",
    "            url = f\"https://www.topcoder.com/challenges/{chl['id']}?tab=registrants\"\n",
    "            driver = WEBDRIVER.getDriver(url)\n",
    "            WebDriverWait(driver, timeout=10).until(EC.presence_of_all_elements_located((By.XPATH, \"//*[@aria-label='Registrants']//a\")))\n",
    "            developers = driver.find_elements(By.XPATH, \"//*[@aria-label='Registrants']//a\")\n",
    "            for _, dev in enumerate(developers):\n",
    "                url = dev.get_attribute('href')\n",
    "                username = dev.text\n",
    "                developersData = {'username':username, \"url\":url}\n",
    "                USER_DATA[0][username]={username: developersData}\n",
    "                saveDevData(USER_DATA)  \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            driver.quit()\n",
    "            continue\n",
    "    saveDevData(USER_DATA)\n",
    "    print(f\"{index}/{len(CHALLENGES)} DEV Found: {len(developers)}\")\n",
    "    print(f\"\\n DEVELOPERS RAW DATA SAVED: \\n'{DEVELOPERS_FILE}'\")\n",
    "    driver.quit()\n",
    "except Exception as e: print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DEVELOPERS TRAITS AND STATISTICS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPERS_PROFILE_FILE = os.path.join(BIN_DIR, \"developerProfiles.json\")\n",
    "if not os.path.exists(DEVELOPERS_PROFILE_FILE): \n",
    "    with open(DEVELOPERS_PROFILE_FILE, \"w\") as f: f.write(json.dumps([{}]))\n",
    "\n",
    "def getDeveloper(userName):\n",
    "    url = f\"https://api.topcoder.com/v5/members/{userName}/stats\"\n",
    "    global headers\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers).json()\n",
    "        return response\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def devTraits(username, traitType=\"work\"):\n",
    "    url = f\"https://api.topcoder.com/v5/members/{username}/traits?traitIds={traitType}\"\n",
    "    global headers\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers).json()\n",
    "        if response:\n",
    "            traits = response[0]['traits']\n",
    "            if traits['data']: return traits['data']\n",
    "            return {}\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return {}\n",
    "        \n",
    "def statsAnalysis(devData):\n",
    "    temp = {}\n",
    "    for ky, vlu in devData.items():\n",
    "        if type(vlu) == dict:\n",
    "            if \"challenges\" in vlu.keys(): temp[ky] = {'challenges': vlu['challenges'], 'wins': vlu['wins']}\n",
    "            elif ky==\"maxRating\":\n",
    "                temp['rating'] = vlu['rating']\n",
    "                try: temp['track'] = vlu['track']\n",
    "                except: pass\n",
    "            else: temp[ky] = vlu\n",
    "    return temp\n",
    "\n",
    "def readDevData(path):\n",
    "    readedData = None\n",
    "    with open(path, \"r\") as f:\n",
    "        readedData = json.loads(f.read())\n",
    "    return readedData\n",
    "\n",
    "def saveDevData(data):\n",
    "    with open(DEVELOPERS_PROFILE_FILE, \"w\") as f: f.write(json.dumps(data))\n",
    "\n",
    "\n",
    "DEVELOPERS = readDevData(DEVELOPERS_FILE)\n",
    "STATS = readDevData(DEVELOPERS_PROFILE_FILE)\n",
    "keys = list(DEVELOPERS[0].keys())\n",
    "for index, user in enumerate(tqdm(keys, desc=\"Processing challenges\")):\n",
    "    try:\n",
    "        devData = getDeveloper(user)\n",
    "        devStats = statsAnalysis(devData[0])\n",
    "        workTraits = devTraits(user, \"work\")\n",
    "        educationTraits = devTraits(user, \"education\")\n",
    "        temp = {'username':user}\n",
    "        temp.update(devStats)\n",
    "        temp.update({\"work\": workTraits})\n",
    "        temp.update({\"eduction\": educationTraits})\n",
    "        STATS[0][user] = temp\n",
    "        saveDevData(STATS)\n",
    "        # print(f\"{index}/{len(keys)}\")\n",
    "    except Exception as e:\n",
    "        if \"Failed to resolve 'api.topcoder.com' ([Errno 11001] getaddrinfo failed)\" in str(e):\n",
    "            input(\"Network Problem, Please Reconnect and Press Enter ...\")\n",
    "            continue\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERT DEVELOPERS JSON FILE NTO CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to c:\\Users\\PMLS\\Desktop\\topCoders\\topCoders\\SESSION_24_6_49\\DEVELOPERS_STATS_24_6_54.csv\n"
     ]
    }
   ],
   "source": [
    "try: filePath = DEVELOPERS_PROFILE_FILE\n",
    "except: \n",
    "    print(\"Please Input Path of File in CMD: py convertStats_toCSV.py filePath\")\n",
    "    sys.exit()\n",
    "\n",
    "def readDevData(path):\n",
    "    readedData = None\n",
    "    with open(path, \"r\") as f:\n",
    "        readedData = json.loads(f.read())\n",
    "    return readedData\n",
    "\n",
    "data = readDevData(r\"{}\".format(filePath))\n",
    "usernames = set(k for k in data[0].keys())\n",
    "currentTime = datetime.datetime.now()\n",
    "csv_file_path = os.path.join(WORKING_SESSION, f\"DEVELOPERS_STATS_{currentTime.day}_{currentTime.hour}_{currentTime.minute}.csv\") \n",
    "\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['username', 'url', 'rating', 'track', 'Develop Skill', 'Design Skill', 'Data Science Skill', 'Copilot',\n",
    "                        'Work Company 1', 'Work Industory 1', 'Work Position 1', 'Work cityTown 1', 'Work Status 1',\n",
    "                        'Work Company 2', 'Work Industory 2', 'Work Position 2', 'Work cityTown 2', 'Work Status 2',\n",
    "                        'Work Company 3', 'Work Industory 3', 'Work Position 3', 'Work cityTown 3', 'Work Status 3', \n",
    "                        'Education Major 1', 'Education School 1', 'Education Gratuated 1',\n",
    "                        'Education Major 2', 'Education School 2', 'Education Gratuated 2',\n",
    "                        'Education Major 3', 'Education School 3', 'Education Gratuated 3',\n",
    "                        ])  # Write header\n",
    "\n",
    "    for i in data[0].values():\n",
    "        username = i['username']\n",
    "        url = 'https://www.topcoder.com/members/'+i['username']\n",
    "        rating = i['rating']\n",
    "        try: track = i['track']\n",
    "        except: track = None\n",
    "        developSkill = 'challenges: ' + str(i['DEVELOP']['challenges']) + ' challenges: ' + str(i['DEVELOP']['wins'])\n",
    "        designSkill = 'challenges: ' + str(i['DESIGN']['challenges']) + ' challenges: ' + str(i['DESIGN']['wins'])\n",
    "        dataScienceSkill = 'challenges: ' + str(i['DATA_SCIENCE']['challenges']) + ' challenges: ' + str(i['DATA_SCIENCE']['wins'])\n",
    "        try: CopilitSkill = '  '.join([f\"{ky}: {val}\" for ky, val in i['COPILOT'].items()])\n",
    "        except: CopilitSkill = None\n",
    "\n",
    "        if i['work']:\n",
    "            workCompany = [x['company'] for x in i['work']]\n",
    "            try: workIndustry = [x['industry'] for x in i['work']]\n",
    "            except: workIndustry = [None for x in range(0, len(workCompany))]\n",
    "            try: workPosition = [x['position'] for x in i['work']]\n",
    "            except: workPosition = [None for x in range(0, len(workCompany))]\n",
    "            try: workCityTowny = [x['cityTown'] for x in i['work']]\n",
    "            except: workCityTowny = [None for x in range(0, len(workCompany))]\n",
    "            try: workStatus = [x['working'] for x in i['work']]\n",
    "            except: workStatus = [None for x in range(0, len(workCompany))]\n",
    "        else:  workCompany = workIndustry = workPosition = workCityTowny = workStatus = []\n",
    "\n",
    "        workCompany1, workCompany2, workCompany3 = None, None, None\n",
    "        workIndustry1, workIndustry2, workIndustry3 = None, None, None\n",
    "        workPosition1, workPosition2, workPosition3 = None, None, None\n",
    "        workCityTowny1, workCityTowny2, workCityTowny3 = None, None, None\n",
    "        workStatus1, workStatus2, workStatus3 = None, None, None\n",
    "\n",
    "        for wk in range(0, len(workCompany)):\n",
    "            if wk == 0: workCompany1, workIndustry1, workPosition1, workCityTowny1, workStatus1 = workCompany[wk], workIndustry[wk], workPosition[wk], workCityTowny[wk], workStatus[wk]\n",
    "            if wk == 1: workCompany2, workIndustry2, workPosition2, workCityTowny2, workStatus2 = workCompany[wk], workIndustry[wk], workPosition[wk], workCityTowny[wk], workStatus[wk]\n",
    "            if wk == 2: workCompany3, workIndustry3, workPosition3, workCityTowny3, workStatus3 = workCompany[wk], workIndustry[wk], workPosition[wk], workCityTowny[wk], workStatus[wk]\n",
    "\n",
    "        try:\n",
    "            eductionMajors = [x['major'] for x in i['education']]\n",
    "            eductionSchoolName = [x['schoolCollegeName'] for x in i['education']]\n",
    "            eductionGratuated = [x['graduated'] for x in i['education']]\n",
    "        except: eductionMajors = eductionSchoolName = eductionGratuated = []\n",
    "\n",
    "        eductionMajors1, eductionMajors2, eductionMajors3 = None, None, None\n",
    "        eductionSchoolName1, eductionSchoolName2, eductionSchoolName3 = None, None, None\n",
    "        eductionGratuated1, eductionGratuated2, eductionGratuated3 = None, None, None\n",
    "\n",
    "        for wk in range(0, len(eductionMajors)):\n",
    "            if wk == 0: eductionMajors1, eductionSchoolName1, eductionGratuated1 = eductionMajors[wk], eductionSchoolName[wk], eductionGratuated[wk]\n",
    "            if wk == 1: eductionMajors2, eductionSchoolName2, eductionGratuated2 = eductionMajors[wk], eductionSchoolName[wk], eductionGratuated[wk]\n",
    "            if wk == 2: eductionMajors3, eductionSchoolName3, eductionGratuated3 = eductionMajors[wk], eductionSchoolName[wk], eductionGratuated[wk]\n",
    "\n",
    "        \n",
    "        csvwriter.writerow([username, url,rating, track, developSkill, designSkill, dataScienceSkill, CopilitSkill, \n",
    "                            workCompany1, workIndustry1, workPosition1, workCityTowny1, workStatus1,\n",
    "                            workCompany2, workIndustry2, workPosition2, workCityTowny2, workStatus2,\n",
    "                            workCompany3, workIndustry3, workPosition3, workCityTowny3, workStatus3,\n",
    "                            eductionMajors1, eductionSchoolName1, eductionGratuated1,\n",
    "                            eductionMajors2, eductionSchoolName2, eductionGratuated2,\n",
    "                            eductionMajors3, eductionSchoolName3, eductionGratuated3,\n",
    "                            ])\n",
    "\n",
    "\n",
    "print(f'CSV file saved to {csv_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
